# --------------------------------------------------------------------------------------
# Part of the interTwin Project: https://www.intertwin.eu/
#
# Created by: Matteo Bunino
#
# Credit:
# - Jarl Sondre SÃ¦ther <jarl.sondre.saether@cern.ch> - CERN
# - Henry Mutegeki <henry.mutegeki@cern.ch> - CERN
# - Iacopo Ferrario <iacopofederico.ferrario@eurac.edu> - EURAC
# - Matteo Bunino <matteo.bunino@cern.ch> - CERN
# - Linus Maximilian Eickhoff <linus.maximilian.eickhoff@cern.ch> - CERN
# --------------------------------------------------------------------------------------

#! change run or exp name for each user on JSC (overwrite will fail due to permissions)
# General configuration
experiment_name: "vega-train-eurac"
run_id: "vega-train-eurac-1"

work_dir: /ceph/hpc/data/st2301-itwin-users/eurac/model

train_temporal_range: ["2019-01-01", "2019-12-31"]
valid_temporal_range: ["2020-01-01", "2020-12-31"]
test_temporal_range: ["2019-01-01", "2020-12-31"]

seed: 10 

# === Model ===

model: CudaLSTM

hidden_size: 256
dropout: 0.2
lstm_layers: 2
lstm_batch_norm: False

model_head_layer: regression # distr_normal
model_head_activation: linear
model_head_kwargs: {}

find_unused_parameters: False
  
# === Training ===

strategy: ddp

hython_trainer: rnntrainer

loss_fn:
  _target_: hython.losses.RMSELoss
metric_fn:
  _target_: hython.metrics.MSEMetric
# TODO: Hython Metrics dont have a __name__ attribute, please add, so this is not needed:
metric_name: MSEMetric

optimizer: adam

lr_scheduler: null # needed in TrainingConfiguration
lr_scheduler_hython:
  mode: min
  factor: 0.5
  patience: 10

seq_length: 180

learning_rate: 0.001

batch: 512

epochs: 2
time_ray: False

gradient_clip:
    max_norm: 1

target_weights: even # null, even, or dict

# which steps are used in the computation of the loss function
predict_steps: 0 # all # (prediction: 0 = t ), ( forecasts: 1 = t+1, 2 = t + 2)


# > Donwsampling < 

# static 
train_downsampler: #null
  _target_: hython.sampler.downsampler.RandomDownsampler
  frac_time: null
  frac_space: 0.1

valid_downsampler: #null
  _target_: hython.sampler.downsampler.RandomDownsampler
  frac_time: null
  frac_space: 0.1

test_downsampler: null


#  dynamic 
dynamic_downsampler:
    frac_time: 0.5

# === Data ===
data_lazy_load: False
dataset: WflowSBM_HPC
num_workers_dataloader: 4

# === Ray HPO ===
num_workers_per_trial: 1
cpu_per_worker: 6
gpu_per_worker: 1 # 0. - 1
trials: 4


data_source:
  file:
    static_inputs: /ceph/hpc/data/st2301-itwin-users/eurac/eobs_static.zarr
    dynamic_inputs: /ceph/hpc/data/st2301-itwin-users/eurac/eobs_dynamic.zarr
    target_variables: /ceph/hpc/data/st2301-itwin-users/eurac/input/eobs_dynamic.zarr
# s3:
  #   url: https://eurac-eo.s3.amazonaws.com/INTERTWIN/SURROGATE_INPUT/adg1km_eobs_preprocessed.zarr/

static_categorical_inputs:
   - wflow_landuse
   - wflow_soil

static_inputs:
  - thetaS
  - thetaR
  - KsatVer
  - c

dynamic_inputs:
  - precip
  - pet
  - temp
  
target_variables:
  - vwc

mask_variables:
  - mask_missing
  - mask_lake

# Scaling

scaling_variant: minmax
scaling_use_cached: True

# MLFLow
tracking_uri: null # http://mlflow.intertwin.fedcloud.eu/

model_logger:
  CudaLSTM:
      logger: local
      model_component: model # the main model
      model_name: ${model}
      model_uri: ${work_dir}/${experiment_name}_${run_id}/${model}.pt
      log: True
      load: False

training:
  _target_: itwinai.pipeline.Pipeline
  steps:
    - _target_: itwinai.plugins.hython.data.RNNDatasetGetterAndPreprocessor
      hython_trainer: ${hython_trainer}
      dynamic_inputs: ${dynamic_inputs}
      static_inputs: ${static_inputs}
      target_variables: ${target_variables}
      mask_variables: ${mask_variables}
      train_temporal_range: ${train_temporal_range}
      valid_temporal_range: ${valid_temporal_range}
      dataset: ${dataset}
      data_lazy_load: ${data_lazy_load}
      data_source: ${data_source}
      scaling_variant: ${scaling_variant}
      scaling_use_cached: ${scaling_use_cached}
      experiment_name: ${experiment_name}
      run_id: ${run_id}
      work_dir: ${work_dir}
      train_downsampler: ${train_downsampler}
      valid_downsampler: ${valid_downsampler}
      seq_length: ${seq_length}
    - _target_: itwinai.plugins.hython.trainer.RNNDistributedTrainer
      model: ${model}
      config:
        experiment: ${experiment_name}/${run_id}
        experiment_name: ${experiment_name}
        run_id: ${run_id}
        work_dir: ${work_dir}
        batch_size: ${batch}
        learning_rate: ${learning_rate}
        num_workers_dataloader: ${num_workers_dataloader}
        pin_gpu_memory: True
        hython_trainer: ${hython_trainer}
        dynamic_downsampler: ${dynamic_downsampler}
        seq_length: ${seq_length}
        target_variables: ${target_variables}
        dynamic_inputs: ${dynamic_inputs}
        static_inputs: ${static_inputs}

        optimizer: ${optimizer}
        lr_scheduler: ${lr_scheduler}
        target_weights: ${target_weights}

        # model config
        hidden_size: ${hidden_size}
        dropout: ${dropout}
        lstm_layers: ${lstm_layers}
        lstm_batch_norm: ${lstm_batch_norm}

        model_head_layer: ${model_head_layer}
        model_head_activation: ${model_head_activation}
        model_head_kwargs: ${model_head_kwargs}

        loss_fn: ${loss_fn}
        metric_fn: ${metric_fn}
        metric_name: ${metric_name}

        gradient_clip: ${gradient_clip}

        predict_steps: ${predict_steps}

        # model logger
        model_logger: ${model_logger}
        
      strategy: ${strategy}
      epochs: ${epochs}
      measure_gpu_data: True
      measure_communication_overhead: True
      measure_epoch_time: True
      run_id: $(run_id)
      random_seed: ${seed}
      profiling_wait_epochs: 1
      profiling_warmup_epochs: 1
      logger:
        _target_: itwinai.loggers.LoggersCollection
        loggers:
          - _target_: itwinai.loggers.ConsoleLogger
            log_freq: 1
          - _target_: itwinai.loggers.MLFlowLogger
            experiment_name: ${experiment_name}
            run_name: ${run_id}
            log_freq: batch
            tracking_uri: ${tracking_uri}

hpo:
  _target_: itwinai.pipeline.Pipeline
  steps:
    - _target_: itwinai.plugins.hython.data.RNNDatasetGetterAndPreprocessor
      hython_trainer: ${hython_trainer}
      dynamic_inputs: ${dynamic_inputs}
      static_inputs: ${static_inputs}
      target_variables: ${target_variables}
      mask_variables: ${mask_variables}
      train_temporal_range: ${train_temporal_range}
      valid_temporal_range: ${valid_temporal_range}
      dataset: ${dataset}
      data_lazy_load: ${data_lazy_load}
      data_source: ${data_source}
      scaling_variant: ${scaling_variant}
      scaling_use_cached: ${scaling_use_cached}
      experiment_name: ${experiment_name}
      run_id: ${run_id}
      work_dir: ${work_dir}
      train_downsampler: ${train_downsampler}
      valid_downsampler: ${valid_downsampler}
    - _target_: itwinai.plugins.hython.trainer.RNNDistributedTrainer
      model: ${model}
      config:
        experiment: ${experiment_name}/${run_id}
        experiment_name: ${experiment_name}
        run_id: ${run_id}
        work_dir: ${work_dir}
        batch_size: ${batch}
        learning_rate: ${learning_rate}
        num_workers_dataloader: ${num_workers_dataloader}
        pin_gpu_memory: True
        hython_trainer: ${hython_trainer}
        seq_length: ${seq_length}
        target_variables: ${target_variables}
        dynamic_inputs: ${dynamic_inputs}
        static_inputs: ${static_inputs}

        optimizer: ${optimizer}
        lr_scheduler: ${lr_scheduler}
        target_weights: ${target_weights}

        # model config


        hidden_size: ${hidden_size}
        dropout: ${dropout}
        lstm_layers: ${lstm_layers}
        lstm_batch_norm: ${lstm_batch_norm}

        model_head_layer: ${model_head_layer}
        model_head_activation: ${model_head_activation}
        model_head_kwargs: ${model_head_kwargs}

        loss_fn: ${loss_fn}
        metric_fn: ${metric_fn}
        metric_name: ${metric_name}

        gradient_clip: ${gradient_clip}

        predict_steps: ${predict_steps}

        # model logger
        model_logger: ${model_logger}
        
      time_ray: ${time_ray}
      strategy: ${strategy}
      epochs: ${epochs}
      measure_gpu_data: True
      measure_communication_overhead: True
      measure_epoch_time: True
      run_id: $(run_id)
      random_seed: ${seed}
      profiling_wait_epochs: 1
      profiling_warmup_epochs: 1
      logger:
        _target_: itwinai.loggers.LoggersCollection
        loggers:
          - _target_: itwinai.loggers.ConsoleLogger
            log_freq: 1
          - _target_: itwinai.loggers.MLFlowLogger
            experiment_name: ${experiment_name}
            run_name: ${run_id}
            log_freq: batch
            tracking_uri: ${tracking_uri}
                    
      ray_scaling_config:
        _target_: ray.train.ScalingConfig
        num_workers: ${num_workers_per_trial}
        use_gpu: true
        resources_per_worker:
          CPU: ${cpu_per_worker}
          GPU: ${gpu_per_worker}
      ray_tune_config:
        _target_: ray.tune.TuneConfig
        num_samples: ${trials}
        scheduler: null
        #   _target_: ray.tune.schedulers.ASHAScheduler
        #   metric: loss
        #   mode: min
        #   max_t: 5
        #   grace_period: 2
        #   reduction_factor: 6
        #   brackets: 1
      ray_run_config:
        _target_: ray.train.RunConfig
        # storage_path must be an absolute path. Defaulting to the directory from which the
        # job is launched using the itwinai custom OmegaConf resolver ${itwinai.cwd:}
        storage_path: ${itwinai.cwd:}/ray_checkpoints
        name: EURAC-HPO-Experiment
      ray_search_space:
        batch_size:
          type: qrandint
          lower: 128
          upper: 1024
          q: 128
        optim_lr:
          type: uniform
          lower: 1e-4
          upper: 1e-2
        hidden_size:
          type: randint
          lower: 16
          upper: 512
        dropout:
          type: choice
          categories: [0.1, 0.2, 0.3, 0.4, 0.5]
        seq_length:
          type: qrandint
          lower: 90
          upper: 365
          q: 30
        interval_value:
          type: choice
          categories: [3, 5, 10]
        
